{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b1c4924",
   "metadata": {},
   "source": [
    "# WEB SCRAPING-ASSIGNMENT-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244817c3",
   "metadata": {},
   "source": [
    "# Q.NO.1:- Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21191351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\admin\\anaconda3\\lib\\site-packages (4.7.2)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.0.4)\n",
      "Requirement already satisfied: idna in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: outcome in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\admin\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08a19640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20b5ab46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver =webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e563be4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f266238",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the naukri page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07a40881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering designation and location as required in the question-\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "078899b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ca42166",
   "metadata": {},
   "outputs": [],
   "source": [
    "search =driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53f0e9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e754351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# scraping Job Location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "# scraping Company name from the given page \n",
    "company_tags=driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "# scraping Job experience from the given page\n",
    "experience_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac35b352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06a12687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Exp_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Shell Pvt Ltd</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Shell Pvt Ltd</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Shell Pvt Ltd</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ANZ</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ANZ</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sr. Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>MM STAFFING CAREER CONSULTANTS PRIVATE LIMITED</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Analyst | Neiman Marcus Group</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Talent500</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Analyst II</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Management Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Wells Fargo</td>\n",
       "      <td>1-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Analyst - Data Management</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Job_title         Job_location  \\\n",
       "0                               Data Analyst  Bangalore/Bengaluru   \n",
       "1                               Data Analyst  Bangalore/Bengaluru   \n",
       "2                               Data Analyst  Bangalore/Bengaluru   \n",
       "3                               Data Analyst  Bangalore/Bengaluru   \n",
       "4                               Data Analyst  Bangalore/Bengaluru   \n",
       "5                           Sr. Data Analyst  Bangalore/Bengaluru   \n",
       "6  Senior Data Analyst | Neiman Marcus Group  Bangalore/Bengaluru   \n",
       "7                     Senior Data Analyst II  Bangalore/Bengaluru   \n",
       "8             Senior Data Management Analyst  Bangalore/Bengaluru   \n",
       "9           Senior Analyst - Data Management  Bangalore/Bengaluru   \n",
       "\n",
       "                                     Company_name Exp_required  \n",
       "0                                   Shell Pvt Ltd      2-5 Yrs  \n",
       "1                                   Shell Pvt Ltd      3-5 Yrs  \n",
       "2                                   Shell Pvt Ltd      2-5 Yrs  \n",
       "3                                             ANZ      1-4 Yrs  \n",
       "4                                             ANZ      1-5 Yrs  \n",
       "5  MM STAFFING CAREER CONSULTANTS PRIVATE LIMITED      5-8 Yrs  \n",
       "6                                       Talent500     6-11 Yrs  \n",
       "7                                        Flipkart      2-4 Yrs  \n",
       "8                                     Wells Fargo     1-12 Yrs  \n",
       "9                                       Accenture      5-8 Yrs  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the dataframe from above data-\n",
    "df=pd.DataFrame({'Job_title':job_title,'Job_location':job_location,'Company_name':company_name,'Exp_required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75ef2b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"27be2c1562fc761cdb68470af7e97629\", element=\"59180c6f-944e-4407-9f0c-671d27e2fa54\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"27be2c1562fc761cdb68470af7e97629\", element=\"9e8aebf2-742f-4e2b-8417-2dd033d00c04\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"27be2c1562fc761cdb68470af7e97629\", element=\"1fb69fc7-7417-47ae-a1d5-dbc5ab7e32d0\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"27be2c1562fc761cdb68470af7e97629\", element=\"95d035cb-f7f4-4d76-99ff-a258478a9070\")>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to fetching the url\n",
    "url=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "url[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9d87b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.naukri.com/job-listings-data-analyst-shell-pvt-ltd-bangalore-bengaluru-2-to-5-years-091222501110\n",
      "https://www.naukri.com/job-listings-data-analyst-shell-pvt-ltd-bangalore-bengaluru-3-to-5-years-091222501109\n",
      "https://www.naukri.com/job-listings-data-analyst-shell-pvt-ltd-bangalore-bengaluru-2-to-5-years-091222501111\n",
      "https://www.naukri.com/job-listings-data-analyst-anz-support-services-india-pvt-ltd-bangalore-bengaluru-1-to-4-years-071222501790\n"
     ]
    }
   ],
   "source": [
    "for i in url[0:4]: #lets provide range to print only top 4 data\n",
    "    print(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7cef87bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6c3c015",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=2\n",
    "for page in range(start,end):\n",
    "    titles=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "    for i in titles:\n",
    "        job_titles.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"fright fs14 btn-secondary br2\"]')   #  to scrap data from next pages as web pages \n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c94b0e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6871d480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Sr. Data Analyst',\n",
       " 'Senior Data Analyst | Neiman Marcus Group',\n",
       " 'Senior Data Analyst II',\n",
       " 'Senior Data Management Analyst',\n",
       " 'Senior Analyst - Data Management',\n",
       " 'Data Analyst',\n",
       " 'Sr Data Analyst - Tableau',\n",
       " 'Project Data Analyst',\n",
       " 'Analyst- Web Data Management',\n",
       " 'Data Analyst, Business Analyst',\n",
       " 'Sr Data Analyst',\n",
       " 'Sr Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Executive - Data Analyst',\n",
       " 'Data Analyst - Power BI',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst I',\n",
       " 'Data Analyst / Product Analyst / Business Analyst',\n",
       " 'Sr Data Analyst - Tableau',\n",
       " 'Senior Data Analyst - Data Modeling/Quality',\n",
       " 'Data Analyst',\n",
       " 'Financial Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Sr . Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Data Analyst / 4 - 7 years / Bangalore',\n",
       " 'Data Analyst',\n",
       " 'Customer Master Data Analyst (SAP SD/MM)',\n",
       " 'Data Analyst - CRM Platform',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst - SQL']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bdb7d5",
   "metadata": {},
   "source": [
    "# Q.NO.2:- Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b6fe29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver =webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bba9a65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b175e6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the naukri page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea635ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering designation and location as required in the question-\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13786965",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61fe8f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "search =driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8fe3eb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f37cc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# scraping Job Location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "# scraping Company name from the given page \n",
    "company_tags=driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6a6b3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a51f62b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, New Delhi, Hyderabad/Secu...</td>\n",
       "      <td>Tata Nexarc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Nagpur, Pune</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist / AI-ML Engineer</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Hitachi Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Manager-Data Science</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AMERICAN EXPRESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ACN - Applied Intelligence - Data Scientist - 09</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, Noida, Kolkata, ...</td>\n",
       "      <td>Mindtree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - II</td>\n",
       "      <td>Bangalore/Bengaluru, India, Mumbai (All Areas)</td>\n",
       "      <td>Bizongo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai</td>\n",
       "      <td>Baker Hughes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Science - Engineering Manager</td>\n",
       "      <td>Bangalore/Bengaluru, New Delhi</td>\n",
       "      <td>Paytm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Job_title  \\\n",
       "0                  Analystics & Modeling Specialist   \n",
       "1                                    Data Scientist   \n",
       "2                                    Data Scientist   \n",
       "3                   Data Scientist / AI-ML Engineer   \n",
       "4                              Manager-Data Science   \n",
       "5  ACN - Applied Intelligence - Data Scientist - 09   \n",
       "6                                    Data Scientist   \n",
       "7                               Data Scientist - II   \n",
       "8                             Senior Data Scientist   \n",
       "9                Data Science - Engineering Manager   \n",
       "\n",
       "                                        Job_location      Company_name  \n",
       "0  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...         Accenture  \n",
       "1  Bangalore/Bengaluru, New Delhi, Hyderabad/Secu...       Tata Nexarc  \n",
       "2                  Bangalore/Bengaluru, Nagpur, Pune     Tech Mahindra  \n",
       "3                                Bangalore/Bengaluru      Hitachi Ltd.  \n",
       "4                                Bangalore/Bengaluru  AMERICAN EXPRESS  \n",
       "5                                Bangalore/Bengaluru         Accenture  \n",
       "6  Hybrid - Bangalore/Bengaluru, Noida, Kolkata, ...          Mindtree  \n",
       "7     Bangalore/Bengaluru, India, Mumbai (All Areas)           Bizongo  \n",
       "8                        Bangalore/Bengaluru, Mumbai      Baker Hughes  \n",
       "9                     Bangalore/Bengaluru, New Delhi             Paytm  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the dataframe from above data-\n",
    "\n",
    "df=pd.DataFrame({'Job_title':job_title,'Job_location':job_location,'Company_name':company_name})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef34e3b",
   "metadata": {},
   "source": [
    "# Q.NO.3:-In this question We have to scrape data using the filters available on the webpage as shown below:¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8aed5aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver =webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61645941",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a4f92eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the naukri page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de18cbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering designation and location as required in the question-\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef57b6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Delhi/NCR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41aadf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "search =driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a7827412",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "badecac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# scraping Job Location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "# scraping Company name from the given page \n",
    "company_tags=driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "# scraping Job experience from the given page\n",
    "experience_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d2973c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f57756fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Exp_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi / NCR, New Delhi, Hyderabad/Secunderabad...</td>\n",
       "      <td>Tata Nexarc</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hybrid - Noida, Kolkata, Hyderabad/Secunderaba...</td>\n",
       "      <td>Mindtree</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science - Engineering Manager</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>Paytm</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Artificial Intelligence/Computer Vision Engine...</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Vicara</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hybrid - Noida</td>\n",
       "      <td>HCLTech</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Analyst-Data Science</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>AMERICAN EXPRESS</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hiring For DATA Scientist @ NTT DATA Business ...</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...</td>\n",
       "      <td>NTT DATA Business Solutions Private Limited</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist - Machine Learning</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Global Employees</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Bharatpe</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - R / Python / SQL</td>\n",
       "      <td>Delhi / NCR, Mumbai, Gurgaon/Gurugram, Bangalo...</td>\n",
       "      <td>TransOrg Analytics</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0                                     Data Scientist   \n",
       "1                                     Data Scientist   \n",
       "2                 Data Science - Engineering Manager   \n",
       "3  Artificial Intelligence/Computer Vision Engine...   \n",
       "4                                     Data Scientist   \n",
       "5                               Analyst-Data Science   \n",
       "6  Hiring For DATA Scientist @ NTT DATA Business ...   \n",
       "7           Senior Data Scientist - Machine Learning   \n",
       "8                           Principal Data Scientist   \n",
       "9                  Data Scientist - R / Python / SQL   \n",
       "\n",
       "                                        Job_location  \\\n",
       "0  Delhi / NCR, New Delhi, Hyderabad/Secunderabad...   \n",
       "1  Hybrid - Noida, Kolkata, Hyderabad/Secunderaba...   \n",
       "2                     New Delhi, Bangalore/Bengaluru   \n",
       "3  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...   \n",
       "4                                     Hybrid - Noida   \n",
       "5                                   Gurgaon/Gurugram   \n",
       "6  Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...   \n",
       "7  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...   \n",
       "8                                   Gurgaon/Gurugram   \n",
       "9  Delhi / NCR, Mumbai, Gurgaon/Gurugram, Bangalo...   \n",
       "\n",
       "                                  Company_name Exp_required  \n",
       "0                                  Tata Nexarc      4-8 Yrs  \n",
       "1                                     Mindtree     5-10 Yrs  \n",
       "2                                        Paytm      3-5 Yrs  \n",
       "3                                       Vicara      1-3 Yrs  \n",
       "4                                      HCLTech      4-9 Yrs  \n",
       "5                             AMERICAN EXPRESS      1-5 Yrs  \n",
       "6  NTT DATA Business Solutions Private Limited      4-9 Yrs  \n",
       "7                             Global Employees     7-12 Yrs  \n",
       "8                                     Bharatpe      5-8 Yrs  \n",
       "9                           TransOrg Analytics      3-6 Yrs  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the dataframe from above data-\n",
    "df=pd.DataFrame({'Job_title':job_title,'Job_location':job_location,'Company_name':company_name,'Exp_required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83952ef",
   "metadata": {},
   "source": [
    "# Q.NO.4:- Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "be4e0723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver =webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b483a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "506374dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the flipkart page on automated chrome browser\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9315317d",
   "metadata": {},
   "outputs": [],
   "source": [
    "product=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "product.send_keys('Sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "301cacbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"_34RNph\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cbdcaa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=[]\n",
    "prod_description=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c1dcbbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping product brands from the given page\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    brands=driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\")\n",
    "    for i in brands[0:100]:\n",
    "        brand.append(i.text)\n",
    "\n",
    "#scraping Product descriptions from the given page        \n",
    "    Product_desc=driver.find_elements(By.XPATH,\"//a[@class='IRpwTa']\")   \n",
    "    for i in Product_desc[0:100]:\n",
    "        prod_description.append(i.text)\n",
    "        \n",
    "#scraping Product prices from the given page    \n",
    "    prices=driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "    for i in prices[0:100]:\n",
    "        price.append(i.text)\n",
    "    next_button=driver.find_elements(By.XPATH,\"//div[@class='_1LKTO3']\")    \n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1569a0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120\n"
     ]
    }
   ],
   "source": [
    "print(len(brand),len(prod_description),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "febaa6ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Prod_description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection, Mirrored Wayfarer Sunglasses (54)</td>\n",
       "      <td>₹179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Retro Square Sunglasse...</td>\n",
       "      <td>₹549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LIZA ANGEL</td>\n",
       "      <td>Riding Glasses, Night Vision Spectacle Sunglas...</td>\n",
       "      <td>₹129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PHENOMENAL</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (53)</td>\n",
       "      <td>₹129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>Gradient, Toughened Glass Lens, UV Protection ...</td>\n",
       "      <td>₹597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Cat-eye S...</td>\n",
       "      <td>₹949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (52)</td>\n",
       "      <td>₹209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Brand                                   Prod_description Price\n",
       "0         Elligator   UV Protection, Mirrored Wayfarer Sunglasses (54)  ₹179\n",
       "1    ROZZETTA CRAFT  UV Protection, Gradient Retro Square Sunglasse...  ₹549\n",
       "2        LIZA ANGEL  Riding Glasses, Night Vision Spectacle Sunglas...  ₹129\n",
       "3          Fastrack   UV Protection Rectangular Sunglasses (Free Size)  ₹489\n",
       "4        PHENOMENAL         UV Protection Retro Square Sunglasses (53)  ₹129\n",
       "..              ...                                                ...   ...\n",
       "115        Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹599\n",
       "116    Singco India  Gradient, Toughened Glass Lens, UV Protection ...  ₹597\n",
       "117   VINCENT CHASE  by Lenskart Polarized, UV Protection Cat-eye S...  ₹949\n",
       "118          PIRASO          UV Protection Rectangular Sunglasses (52)  ₹209\n",
       "119        Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹479\n",
       "\n",
       "[120 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the dataframe from above data-\n",
    "df=pd.DataFrame({'Brand':brand,'Prod_description':prod_description,'Price':price})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0b5f69",
   "metadata": {},
   "source": [
    "# Q.6.Scrape 100 reviews data from flipkart.com for iphone11 phone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7338f99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver =webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "93c54d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4852f860",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the flipkart page on automated chrome browser\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f612fb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "phone=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "phone.send_keys('iphone11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bd5630c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"_34RNph\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "66491453",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating=[]\n",
    "review_summary=[]\n",
    "full_review=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c74e0554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping phone ratings from the given page\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    ratings=driver.find_elements(By.XPATH,\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "    for i in ratings[0:100]:\n",
    "        rating.append(i.text)\n",
    "\n",
    "#scraping Phone reviewsummary from the given page        \n",
    "    Review_summary=driver.find_elements(By.XPATH,\"//p[@class='_2-N8zT']\")   \n",
    "    for i in  Review_summary[0:100]:\n",
    "        review_summary.append(i.text)\n",
    "        \n",
    "#scraping Phone fullreview from the given page    \n",
    "    Full_review=driver.find_elements(By.XPATH,\"//div[@class='t-ZTKy']\")\n",
    "    for i in Full_review[0:100]:\n",
    "        full_review.append(i.text)\n",
    "    next_button=driver.find_elements(By.XPATH,\"//a[@class='_1LKTO3']\")    \n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7e4053b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 24 24\n"
     ]
    }
   ],
   "source": [
    "print(len(rating),len(review_summary),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a5c06aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_Summary</th>\n",
       "      <th>Full_Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>Fast performance to previous iPhone x\\nGood ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Awesome product ❤️❤️\\nThank you Flipkart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>After using 3 years mobile review. Excellent &amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>I am using the phone for last 5 years and foun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>Go for it it will last more than 3/4 years ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>Good quality product</td>\n",
       "      <td>impressively Nice......\\nOne of the greatest i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Nice products thanks flkat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>Fast performance to previous iPhone x\\nGood ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Awesome product ❤️❤️\\nThank you Flipkart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>After using 3 years mobile review. Excellent &amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>I am using the phone for last 5 years and foun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>Go for it it will last more than 3/4 years ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>Good quality product</td>\n",
       "      <td>impressively Nice......\\nOne of the greatest i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Nice products thanks flkat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>Fast performance to previous iPhone x\\nGood ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Awesome product ❤️❤️\\nThank you Flipkart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>After using 3 years mobile review. Excellent &amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>I am using the phone for last 5 years and foun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>Go for it it will last more than 3/4 years ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>Good quality product</td>\n",
       "      <td>impressively Nice......\\nOne of the greatest i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Nice products thanks flkat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating        Review_Summary  \\\n",
       "0       5             Fabulous!   \n",
       "1       5         Great product   \n",
       "2       5      Perfect product!   \n",
       "3       5              Terrific   \n",
       "4       5        Simply awesome   \n",
       "5       5             Must buy!   \n",
       "6       4  Good quality product   \n",
       "7       5      Perfect product!   \n",
       "8       5             Fabulous!   \n",
       "9       5         Great product   \n",
       "10      5      Perfect product!   \n",
       "11      5              Terrific   \n",
       "12      5        Simply awesome   \n",
       "13      5             Must buy!   \n",
       "14      4  Good quality product   \n",
       "15      5      Perfect product!   \n",
       "16      5             Fabulous!   \n",
       "17      5         Great product   \n",
       "18      5      Perfect product!   \n",
       "19      5              Terrific   \n",
       "20      5        Simply awesome   \n",
       "21      5             Must buy!   \n",
       "22      4  Good quality product   \n",
       "23      5      Perfect product!   \n",
       "\n",
       "                                          Full_Review  \n",
       "0   Fast performance to previous iPhone x\\nGood ca...  \n",
       "1            Awesome product ❤️❤️\\nThank you Flipkart  \n",
       "2   After using 3 years mobile review. Excellent &...  \n",
       "3   I am using the phone for last 5 years and foun...  \n",
       "4   Really satisfied with the Product I received.....  \n",
       "5   Go for it it will last more than 3/4 years ins...  \n",
       "6   impressively Nice......\\nOne of the greatest i...  \n",
       "7                          Nice products thanks flkat  \n",
       "8   Fast performance to previous iPhone x\\nGood ca...  \n",
       "9            Awesome product ❤️❤️\\nThank you Flipkart  \n",
       "10  After using 3 years mobile review. Excellent &...  \n",
       "11  I am using the phone for last 5 years and foun...  \n",
       "12  Really satisfied with the Product I received.....  \n",
       "13  Go for it it will last more than 3/4 years ins...  \n",
       "14  impressively Nice......\\nOne of the greatest i...  \n",
       "15                         Nice products thanks flkat  \n",
       "16  Fast performance to previous iPhone x\\nGood ca...  \n",
       "17           Awesome product ❤️❤️\\nThank you Flipkart  \n",
       "18  After using 3 years mobile review. Excellent &...  \n",
       "19  I am using the phone for last 5 years and foun...  \n",
       "20  Really satisfied with the Product I received.....  \n",
       "21  Go for it it will last more than 3/4 years ins...  \n",
       "22  impressively Nice......\\nOne of the greatest i...  \n",
       "23                         Nice products thanks flkat  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the dataframe from above data-\n",
    "df=pd.DataFrame({'Rating':rating,'Review_Summary':review_summary,'Full_Review':full_review})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2daeb56",
   "metadata": {},
   "source": [
    "# Q.NO.7:-Go to webpage https://www.amazon.in/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21f1a31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\admin\\anaconda3\\lib\\site-packages (4.7.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: outcome in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: idna in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.0.4)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\admin\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b48b7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29100cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver =webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92b59c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b9dfed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the flipkart page on automated chrome browser\n",
    "driver.get(\"https://www.amazon.in//\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baca201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "product=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")\n",
    "product.send_keys('laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "beb7f917",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty lists\n",
    "laptop_title=[]\n",
    "laptop_rating=[]\n",
    "laptop_price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0d22e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping brand of laptop from the given page\n",
    "laptop_tags=driver.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for i in laptop_tags[0:40]:\n",
    "    title=i.text\n",
    "    laptop_title.append(title)\n",
    "    \n",
    "    \n",
    "# scraping ratings of laptop from the given page\n",
    "product_ratings=driver.find_elements(By.XPATH,\"//a[@class='a-popover-trigger a-declarative']\")\n",
    "for i in product_ratings[0:40]:\n",
    "    ratings=i.text\n",
    "    laptop_rating.append(ratings)\n",
    "    \n",
    "    \n",
    "# scraping price of laptop name from the given page \n",
    "price_tags=driver.find_elements(By.XPATH,\"//span[@class='a-price-whole']\")\n",
    "for i in price_tags[0:40]:\n",
    "    price=i.text\n",
    "    laptop_price.append(price)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3554aa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigating to the next page\n",
    "next_page=driver.find_element(By.XPATH,'//a[@class=\"s-pagination-item s-pagination-next s-pagination-button s-pagination-separator\"]')\n",
    "next_page.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29f1bc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 36 38\n"
     ]
    }
   ],
   "source": [
    "print(len(laptop_title),len(laptop_rating),len(laptop_price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85e536c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laptop_Title</th>\n",
       "      <th>Laptop_Rating</th>\n",
       "      <th>Laptop_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP Pavilion x360 11th Gen Intel Core i7 14 inc...</td>\n",
       "      <td></td>\n",
       "      <td>82,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acer Swift 5 Intel Evo Premium 14 Inches Full ...</td>\n",
       "      <td></td>\n",
       "      <td>1,05,385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 12th Gen Intel Core i7 1...</td>\n",
       "      <td></td>\n",
       "      <td>82,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP Pavilion x360 11th Gen Intel Core i7 14 inc...</td>\n",
       "      <td></td>\n",
       "      <td>82,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fujitsu UH-X 11th Gen Intel Core i7 13.3” FHD ...</td>\n",
       "      <td></td>\n",
       "      <td>79,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...</td>\n",
       "      <td></td>\n",
       "      <td>95,546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(Renewed) HP ProBook 430 G3 6th Gen Intel Core...</td>\n",
       "      <td></td>\n",
       "      <td>24,939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dell New Windows 11 G15 5520 Gaming Laptop, In...</td>\n",
       "      <td></td>\n",
       "      <td>1,25,890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ASUS TUF Dash F15 (2022), 15.6-inch (39.62 cms...</td>\n",
       "      <td></td>\n",
       "      <td>1,49,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Renewed) HP ProBook 430 G3 6th Gen Intel Core...</td>\n",
       "      <td></td>\n",
       "      <td>22,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 12th Gen Core i7 15....</td>\n",
       "      <td></td>\n",
       "      <td>91,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...</td>\n",
       "      <td></td>\n",
       "      <td>61,499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HP Victus Gaming Latest 12th Gen Intel Core i7...</td>\n",
       "      <td></td>\n",
       "      <td>82,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ASUS TUF Gaming F15 (2022), 15.6\"(39.62 cms) F...</td>\n",
       "      <td></td>\n",
       "      <td>1,00,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...</td>\n",
       "      <td></td>\n",
       "      <td>61,499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Lenovo Ideapad Gaming 3 Intel Core i7 10th Gen...</td>\n",
       "      <td></td>\n",
       "      <td>71,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Acer Nitro 5 Gaming Laptop Intel core i7 11th ...</td>\n",
       "      <td></td>\n",
       "      <td>79,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DELL Alienware x14 Gaming Laptop, Intel i7-127...</td>\n",
       "      <td></td>\n",
       "      <td>1,64,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...</td>\n",
       "      <td></td>\n",
       "      <td>89,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td></td>\n",
       "      <td>53,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Fujitsu UH-X 12th Gen Intel Evo Core i7 13.3 i...</td>\n",
       "      <td></td>\n",
       "      <td>99,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MSI Titan GT77 12UHS, Intel 12th Gen. Core i7 ...</td>\n",
       "      <td></td>\n",
       "      <td>4,82,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>HP Pavilion 14 11th Gen Intel Core i7 16GB/1TB...</td>\n",
       "      <td></td>\n",
       "      <td>91,600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Lenovo ThinkPad E14 Intel Core i7 12th Gen 14\"...</td>\n",
       "      <td></td>\n",
       "      <td>95,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ASUS TUF Gaming F17 (2022), 17.3\"(43.94 cms) F...</td>\n",
       "      <td></td>\n",
       "      <td>1,06,874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Laptop_Title Laptop_Rating  \\\n",
       "0   HP Pavilion x360 11th Gen Intel Core i7 14 inc...                 \n",
       "1   Acer Swift 5 Intel Evo Premium 14 Inches Full ...                 \n",
       "2   Lenovo IdeaPad Slim 5 12th Gen Intel Core i7 1...                 \n",
       "3   HP Pavilion x360 11th Gen Intel Core i7 14 inc...                 \n",
       "4   Fujitsu UH-X 11th Gen Intel Core i7 13.3” FHD ...                 \n",
       "5   HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...                 \n",
       "6   (Renewed) HP ProBook 430 G3 6th Gen Intel Core...                 \n",
       "7   Dell New Windows 11 G15 5520 Gaming Laptop, In...                 \n",
       "8   ASUS TUF Dash F15 (2022), 15.6-inch (39.62 cms...                 \n",
       "9   (Renewed) HP ProBook 430 G3 6th Gen Intel Core...                 \n",
       "10  Lenovo ThinkBook 15 Intel 12th Gen Core i7 15....                 \n",
       "11  ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...                 \n",
       "12  HP Victus Gaming Latest 12th Gen Intel Core i7...                 \n",
       "13  ASUS TUF Gaming F15 (2022), 15.6\"(39.62 cms) F...                 \n",
       "14  ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...                 \n",
       "15  Lenovo Ideapad Gaming 3 Intel Core i7 10th Gen...                 \n",
       "16  Acer Nitro 5 Gaming Laptop Intel core i7 11th ...                 \n",
       "17  DELL Alienware x14 Gaming Laptop, Intel i7-127...                 \n",
       "18  HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...                 \n",
       "19  Mi Notebook Horizon Edition 14 Intel Core i7-1...                 \n",
       "20  Fujitsu UH-X 12th Gen Intel Evo Core i7 13.3 i...                 \n",
       "21  MSI Titan GT77 12UHS, Intel 12th Gen. Core i7 ...                 \n",
       "22  HP Pavilion 14 11th Gen Intel Core i7 16GB/1TB...                 \n",
       "23  Lenovo ThinkPad E14 Intel Core i7 12th Gen 14\"...                 \n",
       "24  ASUS TUF Gaming F17 (2022), 17.3\"(43.94 cms) F...                 \n",
       "\n",
       "   Laptop_Price  \n",
       "0        82,490  \n",
       "1      1,05,385  \n",
       "2        82,990  \n",
       "3        82,490  \n",
       "4        79,990  \n",
       "5        95,546  \n",
       "6        24,939  \n",
       "7      1,25,890  \n",
       "8      1,49,900  \n",
       "9        22,999  \n",
       "10       91,490  \n",
       "11       61,499  \n",
       "12       82,490  \n",
       "13     1,00,990  \n",
       "14       61,499  \n",
       "15       71,990  \n",
       "16       79,990  \n",
       "17     1,64,490  \n",
       "18       89,000  \n",
       "19       53,500  \n",
       "20       99,990  \n",
       "21     4,82,990  \n",
       "22       91,600  \n",
       "23       95,990  \n",
       "24     1,06,874  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Laptop_Title':laptop_title[0:25],'Laptop_Rating':laptop_rating[0:25],'Laptop_Price':laptop_price[0:25]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6592e38",
   "metadata": {},
   "source": [
    "# Q8: Write a python program to scrape data for Top 1000 Quotes of All Time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfc9d6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\admin\\anaconda3\\lib\\site-packages (4.7.2)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.0.4)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\admin\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33cd9d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a47e707",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver =webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf7fb932",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41c31b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the azquotes page on automated chrome browser\n",
    "driver.get(\"https://www.azquotes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff886de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div[1]/div/div[2]/div[1]/a\")\n",
    "quotes.send_keys('azquotes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0943d4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty lists\n",
    "quote_title=[]\n",
    "author_name=[]\n",
    "type_quote=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c778ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Quotes from the given page\n",
    "quote_titles=driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "for i in quote_titles[0:10]:\n",
    "    title=i.text\n",
    "    quote_title.append(title)\n",
    "    \n",
    "    \n",
    "# scraping authores of quotes from the given page\n",
    "author_names=driver.find_elements(By.XPATH,\"//div[@class='author']\")\n",
    "for i in author_names[0:10]:\n",
    "    authors=i.text\n",
    "    author_name.append(authors)\n",
    "    \n",
    "    \n",
    "# scraping types of quotes from the given page \n",
    "type_quotes=driver.find_elements(By.XPATH,\"//div[@class='tags']\")\n",
    "for i in type_quotes[0:10]:\n",
    "    typeofquotes=i.text\n",
    "    type_quote.append(typeofquotes)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2007c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigating to the next page\n",
    "next_page=driver.find_element(By.XPATH,'//li[@class=\"next\"]')\n",
    "next_page.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e50e1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 100\n"
     ]
    }
   ],
   "source": [
    "print(len(quote_title),len(author_name),len(type_quotes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a83b20b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote_Title</th>\n",
       "      <th>Author_Name</th>\n",
       "      <th>Type_Quotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can words describe the fragrance of the very b...</td>\n",
       "      <td>Neltje Blanchan</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When everything seems to be going against you,...</td>\n",
       "      <td>Henry Ford</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Faith is to believe what you do not see; the r...</td>\n",
       "      <td>Saint Augustine</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have found that if you love life, life will ...</td>\n",
       "      <td>Arthur Rubinstein</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To disarm the people... was the best and most ...</td>\n",
       "      <td>George Mason</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Today a reader, tomorrow a leader.</td>\n",
       "      <td>Margaret Fuller</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A dream doesn't become reality through magic; ...</td>\n",
       "      <td>Colin Powell</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Whoever would overthrow the liberty of a natio...</td>\n",
       "      <td>Benjamin Franklin</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>It's better to be a lion for a day than a shee...</td>\n",
       "      <td>Elizabeth Kenny</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Resolution One: I will live for God. Resolutio...</td>\n",
       "      <td>Jonathan Edwards</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Quote_Title        Author_Name  \\\n",
       "0  Can words describe the fragrance of the very b...    Neltje Blanchan   \n",
       "1  When everything seems to be going against you,...         Henry Ford   \n",
       "2  Faith is to believe what you do not see; the r...    Saint Augustine   \n",
       "3  I have found that if you love life, life will ...  Arthur Rubinstein   \n",
       "4  To disarm the people... was the best and most ...       George Mason   \n",
       "5                 Today a reader, tomorrow a leader.    Margaret Fuller   \n",
       "6  A dream doesn't become reality through magic; ...       Colin Powell   \n",
       "7  Whoever would overthrow the liberty of a natio...  Benjamin Franklin   \n",
       "8  It's better to be a lion for a day than a shee...    Elizabeth Kenny   \n",
       "9  Resolution One: I will live for God. Resolutio...   Jonathan Edwards   \n",
       "\n",
       "                                         Type_Quotes  \n",
       "0  <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "1  <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "2  <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "3  <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "4  <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "5  <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "6  <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "7  <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "8  <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "9  <selenium.webdriver.remote.webelement.WebEleme...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Quote_Title':quote_title[0:10],'Author_Name':author_name[0:10],'Type_Quotes':type_quotes[0:10]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cfb71b",
   "metadata": {},
   "source": [
    "# Q9: Write a python program to display list of respected former Prime Ministers of India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c17e09b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\admin\\anaconda3\\lib\\site-packages (4.7.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.0.4)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: outcome in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: pycparser in c:\\users\\admin\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffd9fd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ecc60d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver =webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73c14247",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bff5e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the azquotes page on automated chrome browser\n",
    "driver.get(\"https://www.jagranjosh.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d5161ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div/div/div/div[1]/div/div[3]/div/div[1]/header/span\"}\n  (Session info: chrome=108.0.5359.99)\nStacktrace:\nBacktrace:\n\t(No symbol) [0x0024F243]\n\t(No symbol) [0x001D7FD1]\n\t(No symbol) [0x000CD04D]\n\t(No symbol) [0x000FC0B0]\n\t(No symbol) [0x000FC22B]\n\t(No symbol) [0x0012E612]\n\t(No symbol) [0x001185D4]\n\t(No symbol) [0x0012C9EB]\n\t(No symbol) [0x00118386]\n\t(No symbol) [0x000F163C]\n\t(No symbol) [0x000F269D]\n\tGetHandleVerifier [0x004E9A22+2655074]\n\tGetHandleVerifier [0x004DCA24+2601828]\n\tGetHandleVerifier [0x002F8C0A+619850]\n\tGetHandleVerifier [0x002F7830+614768]\n\t(No symbol) [0x001E05FC]\n\t(No symbol) [0x001E5968]\n\t(No symbol) [0x001E5A55]\n\t(No symbol) [0x001F051B]\n\tBaseThreadInitThunk [0x760CFEF9+25]\n\tRtlGetAppContainerNamedObjectPath [0x77777BBE+286]\n\tRtlGetAppContainerNamedObjectPath [0x77777B8E+238]\n\t(No symbol) [0x00000000]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m minister\u001b[38;5;241m=\u001b[39m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/html/body/div/div/div/div[1]/div/div[3]/div/div[1]/header/span\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m minister\u001b[38;5;241m.\u001b[39msend_keys(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgk\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:861\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    858\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    859\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m value\n\u001b[1;32m--> 861\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:444\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    442\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 444\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:249\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    247\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 249\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div/div/div/div[1]/div/div[3]/div/div[1]/header/span\"}\n  (Session info: chrome=108.0.5359.99)\nStacktrace:\nBacktrace:\n\t(No symbol) [0x0024F243]\n\t(No symbol) [0x001D7FD1]\n\t(No symbol) [0x000CD04D]\n\t(No symbol) [0x000FC0B0]\n\t(No symbol) [0x000FC22B]\n\t(No symbol) [0x0012E612]\n\t(No symbol) [0x001185D4]\n\t(No symbol) [0x0012C9EB]\n\t(No symbol) [0x00118386]\n\t(No symbol) [0x000F163C]\n\t(No symbol) [0x000F269D]\n\tGetHandleVerifier [0x004E9A22+2655074]\n\tGetHandleVerifier [0x004DCA24+2601828]\n\tGetHandleVerifier [0x002F8C0A+619850]\n\tGetHandleVerifier [0x002F7830+614768]\n\t(No symbol) [0x001E05FC]\n\t(No symbol) [0x001E5968]\n\t(No symbol) [0x001E5A55]\n\t(No symbol) [0x001F051B]\n\tBaseThreadInitThunk [0x760CFEF9+25]\n\tRtlGetAppContainerNamedObjectPath [0x77777BBE+286]\n\tRtlGetAppContainerNamedObjectPath [0x77777B8E+238]\n\t(No symbol) [0x00000000]\n"
     ]
    }
   ],
   "source": [
    "minister=driver.find_element(By.XPATH,\"/html/body/div/div/div/div[1]/div/div[3]/div/div[1]/header/span\")\n",
    "minister.send_keys('gk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a8d71b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty lists\n",
    "pm_name=[]\n",
    "born_dead=[]\n",
    "term_office=[]\n",
    "pm_remark=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8cd3d63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping pm names from the given page\n",
    "pm_names=driver.find_elements(By.XPATH,\"//div[@class='table-box']/table/tbody/tr[2]/td[2]/p\")\n",
    "for i in pm_names[0:1]:\n",
    "    name=i.text\n",
    "    pm_name.append(name)\n",
    "    \n",
    "    \n",
    "# scraping born-dead date of PM from the given page\n",
    "born_deads=driver.find_elements(By.XPATH,\"//div[@class='table-box']/table/tbody/tr[2]/td[3]/p\")\n",
    "for i in born_deads:\n",
    "    minister=i.text\n",
    "    born_dead.append(minister)\n",
    "    \n",
    "    \n",
    "# scraping term of office from the given page \n",
    "term_offices=driver.find_elements(By.XPATH,\"//div[@class='table-box']/table/tbody/tr[2]/td[4]/p\")\n",
    "for i in term_offices:\n",
    "    termofoffice=i.text\n",
    "    term_office.append(termofoffice)\n",
    "    \n",
    "# scraping Remarks of PM from the given page\n",
    "pm_remarks=driver.find_elements(By.XPATH,\"//div[@class='table-box']/table/tbody/tr[2]/td[5]/p\")\n",
    "for i in pm_remarks:\n",
    "    pm=i.text\n",
    "    pm_remark.append(pm)\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "46314b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 7 9 5\n"
     ]
    }
   ],
   "source": [
    "print(len(pm_name),len(born_dead),len(term_office),len(pm_remark))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f99b6393",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [70]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPm_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mpm_name\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBorn_Dead\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mborn_dead\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTerm_office\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mterm_office\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPm_Remark\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mpm_remark\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:636\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    630\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    631\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    632\u001b[0m     )\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 636\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:502\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    494\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    495\u001b[0m         x\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m    497\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m x\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m    499\u001b[0m     ]\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;66;03m# TODO: can we get rid of the dt64tz special case above?\u001b[39;00m\n\u001b[1;32m--> 502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:120\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:674\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    672\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 674\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    678\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    679\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame({'Pm_name':pm_name,'Born_Dead':born_dead,'Term_office':term_office,'Pm_Remark':pm_remark})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d52921",
   "metadata": {},
   "source": [
    "# Q.NO.10:-Write a python program to display list of 50 Most expensive cars in the world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7bb9b7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\admin\\anaconda3\\lib\\site-packages (4.7.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.0.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: idna in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\admin\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "00a9502b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3618e252",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver =webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1d010488",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ad8ce84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the most expensive cars page on automated chrome browser\n",
    "driver.get(\"https://www.motor1.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fe19f074",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars=driver.find_element(By.XPATH,\"/html/body/div[3]/div[2]/div/div/div[3]/div/div/div/form/button[1]\")\n",
    "cars.send_keys('expensivecars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "98b1e23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty list\n",
    "car_name=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "73bc000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping car names from the given page\n",
    "car_names=driver.find_elements(By.XPATH,'//h3[@class=\"subheader\"]')\n",
    "for i in car_names:\n",
    "    carname=i.text\n",
    "    car_name.append(carname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2835e775",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty list\n",
    "car_price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d390f9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the prices of cars\n",
    "car_prices=driver.find_elements(By.XPATH,\"//div[@class='postBody description e-content']/p/strong\")\n",
    "for i in car_prices:\n",
    "    carprice=i.text\n",
    "    car_price.append(carprice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5920561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_dec=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4b975069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping the description of cars from the given page\n",
    "car_decs=driver.find_elements(By.XPATH,\"/html/body/div[3]/div[7]/div[2]/div[1]/div[2]/div[1]/p[5]\")\n",
    "for i in car_decs:\n",
    "    cardescription=i.text\n",
    "    car_dec.append(cardescription)\n",
    "    time.sleep(3)\n",
    "\n",
    "#for removing the price row which is also included in description data-\n",
    "car_dec=[]\n",
    "for i in range(4,103,2):\n",
    "    car_dec.append(cardescription[i])\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "47b0f2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 51 50\n"
     ]
    }
   ],
   "source": [
    "print(len(car_name),len(car_price),len(car_dec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "10145e86",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [81]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCar_Name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mcar_name\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCar_Price\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mcar_price\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCar_Dec\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mcar_dec\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:636\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    630\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    631\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    632\u001b[0m     )\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 636\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:502\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    494\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    495\u001b[0m         x\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m    497\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m x\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m    499\u001b[0m     ]\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;66;03m# TODO: can we get rid of the dt64tz special case above?\u001b[39;00m\n\u001b[1;32m--> 502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:120\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:674\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    672\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 674\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    678\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    679\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame({'Car_Name':car_name,'Car_Price':car_price,'Car_Dec':car_dec})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c011f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
