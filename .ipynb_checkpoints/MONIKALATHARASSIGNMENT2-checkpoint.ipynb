{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "979b865e",
   "metadata": {},
   "source": [
    "# WEB SCRAPING-ASSIGNMENT-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aeceeab",
   "metadata": {},
   "source": [
    "# Q.NO.1:- Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. \n",
    "You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd8356a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\admin\\anaconda3\\lib\\site-packages (4.7.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: idna in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: outcome in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.0.4)\n",
      "Requirement already satisfied: pycparser in c:\\users\\admin\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a593333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1a19d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver =webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b11c8169",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91b141bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the naukri page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc30b8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering designation and location as required in the question-\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ec3312b",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fb2691a",
   "metadata": {},
   "outputs": [],
   "source": [
    "search =driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dcb2977",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6851031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# scraping Job Location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "# scraping Company name from the given page \n",
    "company_tags=driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "# scraping Job experience from the given page\n",
    "experience_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c05413c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "693e08c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Exp_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Project Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>WSP</td>\n",
       "      <td>0-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Temp. WFH - Bangalore/Bengaluru</td>\n",
       "      <td>Treebo Hotels</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Executive - Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ANZ</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ANZ</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sr. Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>MM STAFFING CAREER CONSULTANTS PRIVATE LIMITED</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Analyst | Neiman Marcus Group</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Talent500</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>Yallas Technology Solutions Opc</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Customer Master Data Analyst (SAP SD/MM)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Cyient</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Analyst II</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Job_title  \\\n",
       "0                       Project Data Analyst   \n",
       "1                               Data Analyst   \n",
       "2                   Executive - Data Analyst   \n",
       "3                               Data Analyst   \n",
       "4                               Data Analyst   \n",
       "5                           Sr. Data Analyst   \n",
       "6  Senior Data Analyst | Neiman Marcus Group   \n",
       "7                        Senior Data Analyst   \n",
       "8   Customer Master Data Analyst (SAP SD/MM)   \n",
       "9                     Senior Data Analyst II   \n",
       "\n",
       "                                        Job_location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                    Temp. WFH - Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                     Company_name Exp_required  \n",
       "0                                             WSP      0-4 Yrs  \n",
       "1                                   Treebo Hotels      1-5 Yrs  \n",
       "2                                        Flipkart      1-5 Yrs  \n",
       "3                                             ANZ      1-4 Yrs  \n",
       "4                                             ANZ      1-5 Yrs  \n",
       "5  MM STAFFING CAREER CONSULTANTS PRIVATE LIMITED      5-8 Yrs  \n",
       "6                                       Talent500     6-11 Yrs  \n",
       "7                 Yallas Technology Solutions Opc      2-7 Yrs  \n",
       "8                                          Cyient      2-5 Yrs  \n",
       "9                                        Flipkart      2-4 Yrs  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the dataframe from above data-\n",
    "df=pd.DataFrame({'Job_title':job_title,'Job_location':job_location,'Company_name':company_name,'Exp_required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42dc50aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"7899a7c3ca3b94cdc2c3cf445ee0f287\", element=\"74f0b8bb-248c-4410-b6c3-7b8059d6052a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"7899a7c3ca3b94cdc2c3cf445ee0f287\", element=\"97b91c12-ff0a-496b-b7aa-620d664ff711\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"7899a7c3ca3b94cdc2c3cf445ee0f287\", element=\"ca3d16f4-9627-43cf-9bbb-cd61cff793a9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"7899a7c3ca3b94cdc2c3cf445ee0f287\", element=\"5460e569-6b32-4d9f-9bf8-0006cd4ed63e\")>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to fetching the url\n",
    "url=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "url[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acbf9daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.naukri.com/job-listings-project-data-analyst-wsp-bangalore-bengaluru-0-to-4-years-061222010759\n",
      "https://www.naukri.com/job-listings-data-analyst-treebo-hotels-bangalore-bengaluru-1-to-5-years-061222003847\n",
      "https://www.naukri.com/job-listings-executive-data-analyst-flipkart-internet-private-limited-bangalore-bengaluru-1-to-5-years-061222908060\n",
      "https://www.naukri.com/job-listings-data-analyst-anz-support-services-india-pvt-ltd-bangalore-bengaluru-1-to-4-years-071222501790\n"
     ]
    }
   ],
   "source": [
    "for i in url[0:4]: #lets provide range to print only top 4 data\n",
    "    print(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9ce64ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bee19bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=2\n",
    "for page in range(start,end):\n",
    "    titles=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "    for i in titles:\n",
    "        job_titles.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"fright fs14 btn-secondary br2\"]')   #  to scrap data from next pages as web pages \n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ceb6bf87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df1b9dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Project Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Executive - Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Sr. Data Analyst',\n",
       " 'Senior Data Analyst | Neiman Marcus Group',\n",
       " 'Senior Data Analyst',\n",
       " 'Customer Master Data Analyst (SAP SD/MM)',\n",
       " 'Senior Data Analyst II',\n",
       " 'Senior Data Management Analyst',\n",
       " 'Senior Analyst - Data Management',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst - SQL',\n",
       " 'Sr Data Analyst - Tableau',\n",
       " 'Analyst- Web Data Management',\n",
       " 'Data Analyst, Business Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Sr Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Data Analyst - Power BI',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst I',\n",
       " 'Data Analyst - SQL',\n",
       " 'Data Analyst / Product Analyst / Business Analyst',\n",
       " 'Sr Data Analyst - Tableau',\n",
       " 'Data Analyst/Sr Data Analyst',\n",
       " 'Senior Data Analyst - Data Modeling/Quality',\n",
       " 'Data Analyst',\n",
       " 'Financial Data Analyst',\n",
       " 'Sr . Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Data Analyst / 4 - 7 years / Bangalore',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst - CRM Platform',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst - GAMMA']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e63513",
   "metadata": {},
   "source": [
    "# Q.NO.2:- Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. \n",
    "You have to scrape the job-title, job-location, company_name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0de4b311",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver =webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c067a3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f082bd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the naukri page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "060b42cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering designation and location as required in the question-\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f87131ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "413dd161",
   "metadata": {},
   "outputs": [],
   "source": [
    "search =driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7958334",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06871b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# scraping Job Location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "# scraping Company name from the given page \n",
    "company_tags=driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1296816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37ef873d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, New Delhi, Hyderabad/Secu...</td>\n",
       "      <td>Tata Nexarc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Nagpur, Pune</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist / AI-ML Engineer</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Hitachi Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Manager-Data Science</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AMERICAN EXPRESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ACN - Applied Intelligence - Data Scientist - 09</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, Noida, Kolkata, ...</td>\n",
       "      <td>Mindtree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - II</td>\n",
       "      <td>Bangalore/Bengaluru, India, Mumbai (All Areas)</td>\n",
       "      <td>Bizongo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai</td>\n",
       "      <td>Baker Hughes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Caterpillar Inc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Job_title  \\\n",
       "0                  Analystics & Modeling Specialist   \n",
       "1                                    Data Scientist   \n",
       "2                                    Data Scientist   \n",
       "3                   Data Scientist / AI-ML Engineer   \n",
       "4                              Manager-Data Science   \n",
       "5  ACN - Applied Intelligence - Data Scientist - 09   \n",
       "6                                    Data Scientist   \n",
       "7                               Data Scientist - II   \n",
       "8                             Senior Data Scientist   \n",
       "9                               Lead Data Scientist   \n",
       "\n",
       "                                        Job_location      Company_name  \n",
       "0  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...         Accenture  \n",
       "1  Bangalore/Bengaluru, New Delhi, Hyderabad/Secu...       Tata Nexarc  \n",
       "2                  Bangalore/Bengaluru, Nagpur, Pune     Tech Mahindra  \n",
       "3                                Bangalore/Bengaluru      Hitachi Ltd.  \n",
       "4                                Bangalore/Bengaluru  AMERICAN EXPRESS  \n",
       "5                                Bangalore/Bengaluru         Accenture  \n",
       "6  Hybrid - Bangalore/Bengaluru, Noida, Kolkata, ...          Mindtree  \n",
       "7     Bangalore/Bengaluru, India, Mumbai (All Areas)           Bizongo  \n",
       "8                        Bangalore/Bengaluru, Mumbai      Baker Hughes  \n",
       "9                                Bangalore/Bengaluru   Caterpillar Inc  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the dataframe from above data-\n",
    "\n",
    "df=pd.DataFrame({'Job_title':job_title,'Job_location':job_location,'Company_name':company_name})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0e8156",
   "metadata": {},
   "source": [
    "# Q.NO.3:-In this question We have to scrape data using the filters available on the webpage as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18c10817",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver =webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "236e6ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "caf4e373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the naukri page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34c78710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering designation and location as required in the question-\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4daaf519",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Delhi/NCR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42d06cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "search =driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "42eb6d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ce2d5ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# scraping Job Location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "# scraping Company name from the given page \n",
    "company_tags=driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "# scraping Job experience from the given page\n",
    "experience_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "83c90d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11fbf89a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Exp_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi / NCR, New Delhi, Hyderabad/Secunderabad...</td>\n",
       "      <td>Tata Nexarc</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hybrid - Noida, Kolkata, Hyderabad/Secunderaba...</td>\n",
       "      <td>Mindtree</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science - Engineering Manager</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>Paytm</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Artificial Intelligence/Computer Vision Engine...</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Vicara</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hybrid - Noida</td>\n",
       "      <td>HCLTech</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Analyst-Data Science</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>AMERICAN EXPRESS</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hiring For DATA Scientist @ NTT DATA Business ...</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...</td>\n",
       "      <td>NTT DATA Business Solutions Private Limited</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist - Machine Learning</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Global Employees</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Bharatpe</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - R / Python / SQL</td>\n",
       "      <td>Delhi / NCR, Mumbai, Gurgaon/Gurugram, Bangalo...</td>\n",
       "      <td>TransOrg Analytics</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0                                     Data Scientist   \n",
       "1                                     Data Scientist   \n",
       "2                 Data Science - Engineering Manager   \n",
       "3  Artificial Intelligence/Computer Vision Engine...   \n",
       "4                                     Data Scientist   \n",
       "5                               Analyst-Data Science   \n",
       "6  Hiring For DATA Scientist @ NTT DATA Business ...   \n",
       "7           Senior Data Scientist - Machine Learning   \n",
       "8                           Principal Data Scientist   \n",
       "9                  Data Scientist - R / Python / SQL   \n",
       "\n",
       "                                        Job_location  \\\n",
       "0  Delhi / NCR, New Delhi, Hyderabad/Secunderabad...   \n",
       "1  Hybrid - Noida, Kolkata, Hyderabad/Secunderaba...   \n",
       "2                     New Delhi, Bangalore/Bengaluru   \n",
       "3  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...   \n",
       "4                                     Hybrid - Noida   \n",
       "5                                   Gurgaon/Gurugram   \n",
       "6  Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...   \n",
       "7  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...   \n",
       "8                                   Gurgaon/Gurugram   \n",
       "9  Delhi / NCR, Mumbai, Gurgaon/Gurugram, Bangalo...   \n",
       "\n",
       "                                  Company_name Exp_required  \n",
       "0                                  Tata Nexarc      4-8 Yrs  \n",
       "1                                     Mindtree     5-10 Yrs  \n",
       "2                                        Paytm      3-5 Yrs  \n",
       "3                                       Vicara      1-3 Yrs  \n",
       "4                                      HCLTech      4-9 Yrs  \n",
       "5                             AMERICAN EXPRESS      1-5 Yrs  \n",
       "6  NTT DATA Business Solutions Private Limited      4-9 Yrs  \n",
       "7                             Global Employees     7-12 Yrs  \n",
       "8                                     Bharatpe      5-8 Yrs  \n",
       "9                           TransOrg Analytics      3-6 Yrs  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the dataframe from above data-\n",
    "df=pd.DataFrame({'Job_title':job_title,'Job_location':job_location,'Company_name':company_name,'Exp_required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7627300a",
   "metadata": {},
   "source": [
    "# Q.NO.4:- Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3edd6681",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver =webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e3b1b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7baeae11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the flipkart page on automated chrome browser\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c1560414",
   "metadata": {},
   "outputs": [],
   "source": [
    "product=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "product.send_keys('Sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3a960108",
   "metadata": {},
   "outputs": [
    {
     "ename": "ElementClickInterceptedException",
     "evalue": "Message: element click intercepted: Element <path class=\"_34RNph\" d=\"m11.618 9.897l4.225 4.212c.092.092.101.232.02.313l-1.465 1.46c-.081.081-.221.072-.314-.02l-4.216-4.203\"></path> is not clickable at point (558, 32). Other element would receive the click: <div class=\"_2hriZF _2rbIyg\" tabindex=\"-1\">...</div>\n  (Session info: chrome=108.0.5359.99)\nStacktrace:\nBacktrace:\n\t(No symbol) [0x0112F243]\n\t(No symbol) [0x010B7FD1]\n\t(No symbol) [0x00FAD04D]\n\t(No symbol) [0x00FE28B9]\n\t(No symbol) [0x00FE08CC]\n\t(No symbol) [0x00FDE4CB]\n\t(No symbol) [0x00FDD164]\n\t(No symbol) [0x00FD32A6]\n\t(No symbol) [0x00FF858C]\n\t(No symbol) [0x00FD2BFF]\n\t(No symbol) [0x00FF8804]\n\t(No symbol) [0x0100C9EB]\n\t(No symbol) [0x00FF8386]\n\t(No symbol) [0x00FD163C]\n\t(No symbol) [0x00FD269D]\n\tGetHandleVerifier [0x013C9A22+2655074]\n\tGetHandleVerifier [0x013BCA24+2601828]\n\tGetHandleVerifier [0x011D8C0A+619850]\n\tGetHandleVerifier [0x011D7830+614768]\n\t(No symbol) [0x010C05FC]\n\t(No symbol) [0x010C5968]\n\t(No symbol) [0x010C5A55]\n\t(No symbol) [0x010D051B]\n\tBaseThreadInitThunk [0x7568FEF9+25]\n\tRtlGetAppContainerNamedObjectPath [0x77247BBE+286]\n\tRtlGetAppContainerNamedObjectPath [0x77247B8E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mElementClickInterceptedException\u001b[0m          Traceback (most recent call last)",
      "Input \u001b[1;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m search\u001b[38;5;241m=\u001b[39mdriver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mCLASS_NAME,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_34RNph\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclick\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:93\u001b[0m, in \u001b[0;36mWebElement.click\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclick\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;124;03m\"\"\"Clicks the element.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLICK_ELEMENT\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:410\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    408\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    409\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[1;32m--> 410\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:444\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    442\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 444\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:249\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    247\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 249\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mElementClickInterceptedException\u001b[0m: Message: element click intercepted: Element <path class=\"_34RNph\" d=\"m11.618 9.897l4.225 4.212c.092.092.101.232.02.313l-1.465 1.46c-.081.081-.221.072-.314-.02l-4.216-4.203\"></path> is not clickable at point (558, 32). Other element would receive the click: <div class=\"_2hriZF _2rbIyg\" tabindex=\"-1\">...</div>\n  (Session info: chrome=108.0.5359.99)\nStacktrace:\nBacktrace:\n\t(No symbol) [0x0112F243]\n\t(No symbol) [0x010B7FD1]\n\t(No symbol) [0x00FAD04D]\n\t(No symbol) [0x00FE28B9]\n\t(No symbol) [0x00FE08CC]\n\t(No symbol) [0x00FDE4CB]\n\t(No symbol) [0x00FDD164]\n\t(No symbol) [0x00FD32A6]\n\t(No symbol) [0x00FF858C]\n\t(No symbol) [0x00FD2BFF]\n\t(No symbol) [0x00FF8804]\n\t(No symbol) [0x0100C9EB]\n\t(No symbol) [0x00FF8386]\n\t(No symbol) [0x00FD163C]\n\t(No symbol) [0x00FD269D]\n\tGetHandleVerifier [0x013C9A22+2655074]\n\tGetHandleVerifier [0x013BCA24+2601828]\n\tGetHandleVerifier [0x011D8C0A+619850]\n\tGetHandleVerifier [0x011D7830+614768]\n\t(No symbol) [0x010C05FC]\n\t(No symbol) [0x010C5968]\n\t(No symbol) [0x010C5A55]\n\t(No symbol) [0x010D051B]\n\tBaseThreadInitThunk [0x7568FEF9+25]\n\tRtlGetAppContainerNamedObjectPath [0x77247BBE+286]\n\tRtlGetAppContainerNamedObjectPath [0x77247B8E+238]\n"
     ]
    }
   ],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"_34RNph\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901b1162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping product brands from the given page\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    brands=driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\")\n",
    "    for i in brands[0:100]:\n",
    "        brand.append(i.text)\n",
    "    Product_desc=driver.find_elements(By.XPATH,\"//a[@class='IRpwTa']\")   \n",
    "    for i in Product_desc[0:100]:\n",
    "        prod_description.append(i.text)\n",
    "    prices=driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "    for i in prices[0:100]:\n",
    "        price.append(i.text)\n",
    "    next_button=driver.find_elements(By.XPATH,\"//div[@class='_1LKTO3']\")    \n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432b9ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
